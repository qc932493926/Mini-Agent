# 我的 Mini-Agent 学习问题

> 记录学习 Mini-Agent 项目过程中的问题和思考

## 学习目标

从项目架构角度理解 Mini-Agent 的核心功能运行机制和设计逻辑，最终能从零设计自己的 Agent 框架。

---

## 核心框架公式

```
Agent = LLM + Plan + Tools + Memory
```

**四大组件对应实现：**

- **LLM**：LLMClient 抽象层，支持 Anthropic/OpenAI 协议 → `llm/` 目录
- **Plan**：Agent Loop 循环本身（隐式规划：观察→思考→行动→观察...） → `agent.py:run()`
- **Tools**：Tool 基类 + 具体工具（文件、Bash、MCP、Skill） → `tools/` 目录
- **Memory**：消息历史 `messages` + 摘要机制 + SessionNoteTool → `agent.py` + `note_tool.py`

```
┌─────────────────────────────────────────────────────────────┐
│                    Mini-Agent 架构图                         │
│                                                             │
│    ┌─────────┐      Agent = LLM + Plan + Tools + Memory     │
│    │   CLI   │                                              │
│    └────┬────┘                                              │
│         │                                                   │
│         ▼                                                   │
│    ┌─────────────────────────────────────────────────┐     │
│    │                    Agent                         │     │
│    │  ┌───────────┐  ┌───────────┐  ┌───────────┐   │     │
│    │  │    LLM    │  │   Plan    │  │   Tools   │   │     │
│    │  │ (llm/)    │  │  (Loop)   │  │ (tools/)  │   │     │
│    │  └───────────┘  └───────────┘  └───────────┘   │     │
│    │                 ┌───────────┐                   │     │
│    │                 │  Memory   │                   │     │
│    │                 │(messages) │                   │     │
│    │                 └───────────┘                   │     │
│    └─────────────────────────────────────────────────┘     │
└─────────────────────────────────────────────────────────────┘
```

---

## 学习计划（2026-02-15 制定）

| 阶段 | 时间 | 目标 | 产出 |
|------|------|------|------|
| **阶段1: 整体框架** | 4小时 | 理解项目架构、核心流程、设计决策 | 公众号文章 |
| **阶段2: 动手实践** | 8小时 | 跑最小单元、断点调试、熟悉各环节设计 | 学习笔记 + 代码注释 |
| **阶段3: 复刻应用** | 待定 | 用 spec-kit 项目驱动开发 TS 版本 CLI | TypeScript 版 Mini-Agent |

### 我的背景
- ✅ 熟悉设计模式
- 📚 需要补充：Python 异步编程、LLM API 调用
- 🎯 学习风格：自底向上 + 问题驱动

### 阶段1：4小时学习路线

| 时段 | 内容 | 产出 |
|------|------|------|
| 第1小时 | 跑通 + 建立直觉：运行体验、走通调用链路、绘制架构图 | 核心架构图 |
| 第2小时 | 拆解核心模块：Agent循环、LLM抽象层、工具系统 | 模块关系图 |
| 第3小时 | 理解设计决策：重试机制、消息摘要、MCP协议、配置系统 | 设计要点笔记 |
| 第4小时 | 整理输出：完善图解、撰写文章 | 公众号文章 |

### 文章大纲（公众号输出）

```markdown
# Mini-Agent 源码解析：如何用 500 行代码构建一个 AI Agent

## 一、为什么要读这个项目？（吸引读者）
- MiniMax 官方最佳实践
- 麻雀虽小五脏俱全：Agent Loop、Tool Calling、MCP、重试、摘要

## 二、一图看懂架构（核心价值）
- 架构图 + 数据流图
- 关键模块一句话介绍

## 三、跟着一个请求走一遍（动态理解）
- 用户输入 → CLI → Agent → LLM → Tool → 响应

## 四、三个让我眼前一亮的设计（深度内容）
- 设计1：指数退避重试装饰器
- 设计2：双重 Token 检测触发摘要
- 设计3：MCP 协议的三种连接方式

## 五、如果让我从零写一个？（引发思考）
- 最小可用版本只需要哪些？
- 哪些是锦上添花？
```

---

## 问题列表

### Q1: CLI 文件是怎么来的？修改代码如何快速生效？能否断点调试？

**答：**

1. **CLI 文件来源**
   - 不是编译的，是 Python 模块
   - 通过 `pyproject.toml` 配置：`mini-agent = "mini_agent.cli:main"`
   - 运行 `uv run python -m mini_agent.cli` 即执行 `mini_agent/cli.py`

2. **修改代码快速生效**
   | 方式 | 命令 | 优点 |
   |------|------|------|
   | 方式一（推荐）| `uv tool install -e .` | 代码修改立即生效，无需重装 |
   | 方式二 | `uv run python -m mini_agent.cli` | 每次自动同步依赖 |

3. **断点调试**
   - VSCode：打开 `cli.py` → 设置断点 → 按 F5
   - 命令行：`uv run python -m pdb -m mini_agent.cli`

---

### Q2: 核心调用链路是什么？

**答：**

用户输入 "创建一个 hello.py" 时，代码执行流程：

```
① main()                    cli.py:844
   │
   ▼
② run_agent()               cli.py:486
   ├─ 加载配置               Config.from_yaml()
   ├─ 创建 LLMClient         llm_wrapper.py:36
   ├─ 初始化工具             initialize_base_tools() + add_workspace_tools()
   ├─ 创建 Agent             agent.py:45
   │
   ▼
③ 交互循环                   cli.py:679
   ├─ 获取用户输入            session.prompt_async()
   ├─ agent.add_user_message()
   │
   ▼
④ agent.run()               agent.py:321   ← 核心！
   │
   │  ┌─────────────────────────────────────────────┐
   │  │          Agent Loop (最多 max_steps 轮)      │
   │  │                                             │
   │  │  1. _summarize_messages() - 检查是否需要摘要  │
   │  │  2. llm.generate() ────────► LLM API 调用   │
   │  │  3. 解析响应：                               │
   │  │     ├─ 无 tool_calls → 返回结果，循环结束    │
   │  │     └─ 有 tool_calls → 执行工具，继续循环    │
   │  │  4. tool.execute() ────────► 工具执行       │
   │  │  5. 将工具结果加入消息历史                    │
   │  └─────────────────────────────────────────────┘
   │
   ▼
⑤ 返回最终响应，等待下一次用户输入
```

**关键代码位置：**

| 环节 | 文件 | 行号 | 核心方法 |
|------|------|------|----------|
| 入口 | cli.py | 844 | `main()` |
| 初始化 | cli.py | 486-611 | `run_agent()` |
| Agent循环 | agent.py | 321-519 | `run()` |
| LLM调用 | llm_wrapper.py | 113-127 | `generate()` |
| 工具执行 | agent.py | 461-474 | `tool.execute()` |

---

### Q3: Agent Loop 的本质是什么？

**答：**

Agent 的本质就是：**LLM + 循环 + 工具调用**

```python
while step < self.max_steps:
    # 1. 调用 LLM
    response = await self.llm.generate(messages, tools)

    # 2. 没有工具调用 → 任务完成
    if not response.tool_calls:
        return response.content

    # 3. 有工具调用 → 执行工具，继续循环
    for tool_call in response.tool_calls:
        result = await tool.execute(**arguments)
        self.messages.append(tool_result_message)

    step += 1
```

核心代码位置：`agent.py:343-421`

---

### Q4: Agent Loop 的完整逻辑（取消机制、错误处理）

**答：**

按照 `Agent = LLM + Plan + Tools + Memory` 拆解 `agent.py:run()` 方法：

#### 1. Plan 层：循环控制与状态管理

```python
# agent.py:321-350
async def run(self, cancel_event=None) -> str:
    if cancel_event is not None:
        self.cancel_event = cancel_event

    step = 0
    while step < self.max_steps:        # ← 最大步数限制（默认50）
        if self._check_cancelled():      # ← 取消机制入口
            self._cleanup_incomplete_messages()
            return "Task cancelled by user."
        # ... 执行逻辑
        step += 1
    return f"Task couldn't be completed after {self.max_steps} steps."
```

#### 2. Memory 层：消息历史与摘要

```python
# agent.py:352-353 - 每轮开始时检查是否需要摘要
await self._summarize_messages()
```

**双重 Token 检测**：本地估算 + API 返回，既及时又准确。

#### 3. LLM 层：调用与错误处理

```python
# agent.py:371-383
try:
    response = await self.llm.generate(messages=self.messages, tools=tool_list)
except RetryExhaustedError:
    return f"LLM call failed after {e.attempts} retries"
except Exception as e:
    return f"LLM call failed: {str(e)}"
```

#### 4. Tools 层：工具执行

```python
# agent.py:461-474 - 工具异常不会中断循环，转为失败结果让 LLM 继续决策
try:
    result = await tool.execute(**arguments)
except Exception as e:
    result = ToolResult(success=False, error=f"Tool execution failed: {e}")
```

#### 5. 取消机制流程

```
用户按 Esc → cancel_event.set() → _check_cancelled() 检测（3处）
           → _cleanup_incomplete_messages() 清理残缺消息
           → 返回 "Task cancelled by user."
```

**为什么要清理未完成消息？** 避免消息历史出现残缺的 assistant 消息导致下次 LLM 调用上下文混乱。

---

### Q5: 双层循环与用户交互机制

**答：**

Mini-Agent 有两层循环：

```
┌─────────────────────────────────────────────────────────────────┐
│  cli.py:679   外层循环：用户输入循环                              │
│               while True:                                       │
│                   user_input = await prompt_async()             │
│                   agent.add_user_message(user_input)            │
│                           │                                     │
│                           ▼                                     │
│  agent.py:343   ┌───────────────────────────────────┐          │
│                 │  内层循环：Agent 执行循环          │          │
│                 │  while step < max_steps:          │          │
│                 │      response = llm.generate()    │ ← 用户只能│
│                 │      if no tool_calls: break      │   按Esc取消│
│                 │      execute tools...             │   不能输入 │
│                 │      step += 1                    │          │
│                 └───────────────────────────────────┘          │
│                           │                                     │
│                           ▼                                     │
│               返回结果，回到外层循环等待用户下一次输入             │
└─────────────────────────────────────────────────────────────────┘
```

**关键结论：**

1. **内层循环执行期间，用户无法插入信息**，只能取消或等待完成
2. 补充信息必须在下一轮输入，Agent 会带着完整历史处理

---

### Q6: Mini-Agent 有 TodoList 机制吗？

**答：没有！这是与 Claude Code 的重要区别。**

| 特性 | Mini-Agent | Claude Code |
|------|------------|-------------|
| 规划机制 | **隐式** - LLM 在 thinking 中自行规划 | **显式** - TodoWrite 工具 |
| 用户可见 | 只能看到执行过程 | 可以看到 TodoList |
| 动态调整 | LLM 自己决定下一步 | 用户可以修改 Todo |
| 实现复杂度 | 简单 | 更复杂 |

**Mini-Agent 的 "Plan" 是隐式的**：

```python
# LLM 的 thinking 中（用户看不到显式列表）
"""
用户要找 API Key，我需要：
1. 搜索可能包含 key 的文件
2. 读取 .env 或 config 文件
3. 提取 key 并返回
"""
# 每一步都是 LLM 即时决策，没有显式存储的计划
```

**如果要实现显式 TodoList，需要：**

```python
class AgentWithTodoList:
    def __init__(self):
        self.todos = []  # 显式任务列表

    async def run(self):
        # 1. 先让 LLM 规划
        plan = await self.llm.generate("请规划任务步骤")
        self.todos = parse_plan(plan)

        # 2. 执行每个 Todo，允许中途修改
        for todo in self.todos:
            result = await self.execute_todo(todo)
            if user_wants_to_modify():
                self.todos = user_modify_todos(self.todos)
```

Mini-Agent 选择更简单的方案：**让 LLM 自己在脑子里管理计划**。

---

### Q7: LLM 抽象层设计（策略模式 + 工厂模式）

**答：**

#### 类图结构

```
┌───────────────────┐
│    LLMClient      │  ← 工厂 + 门面
│   (Wrapper)       │
└─────────┬─────────┘
          │ 根据 provider 创建
          ▼
┌───────────────────┐
│  LLMClientBase    │  ← 策略接口（抽象基类）
│     (ABC)         │
│  + generate()     │
│  + _prepare_request()
│  + _convert_messages()
└─────────┬─────────┘
          │
    ┌─────┴─────┐
    │           │
    ▼           ▼
┌─────────┐ ┌─────────┐
│Anthropic│ │ OpenAI  │
│ Client  │ │ Client  │
└─────────┘ └─────────┘
```

#### 涉及的设计模式

| 模式 | 应用位置 | 作用 |
|------|----------|------|
| **策略模式** | `LLMClientBase` + 两个实现类 | 封装不同 API 协议的变化 |
| **工厂模式** | `LLMClient.__init__()` | 根据 provider 创建对应客户端 |
| **模板方法** | `generate()` 流程 | 固定流程（准备→请求→解析），子类实现具体步骤 |
| **适配器模式** | `_convert_messages()` | 统一内部 Message 到不同 API 格式 |

#### 关键代码

```python
# llm_wrapper.py:82-99 - 工厂模式
class LLMClient:
    def __init__(self, api_key, provider, api_base, model, retry_config):
        if provider == LLMProvider.ANTHROPIC:
            self._client = AnthropicClient(...)   # 创建策略 A
        elif provider == LLMProvider.OPENAI:
            self._client = OpenAIClient(...)      # 创建策略 B
```

#### 为什么需要这层抽象？

1. **开闭原则**：新增 Provider 只需加一个类，不改现有代码
2. **单一职责**：每个 Client 只负责自己协议的转换
3. **依赖倒置**：Agent 依赖抽象接口，不依赖具体实现
4. **用户友好**：MiniMax API 自动添加后缀（`/anthropic` 或 `/v1`）

---

### Q8: 工具系统的 Tool 基类设计（命令模式）

**答：**

#### Tool 基类结构

```python
# tools/base.py
class ToolResult(BaseModel):
    success: bool
    content: str = ""
    error: str | None = None

class Tool:
    @property
    def name(self) -> str: ...           # 工具名称
    @property
    def description(self) -> str: ...    # 工具描述（给 LLM 看）
    @property
    def parameters(self) -> dict: ...    # JSON Schema 参数定义

    async def execute(self, **kwargs) -> ToolResult: ...  # 执行逻辑

    def to_schema(self) -> dict: ...           # Anthropic 格式
    def to_openai_schema(self) -> dict: ...    # OpenAI 格式
```

#### 工具类型分类

| 类型 | 实现 | 说明 |
|------|------|------|
| 文件工具 | `ReadTool`, `WriteTool`, `EditTool` | 文件操作 |
| 命令工具 | `BashTool`, `BashOutputTool`, `BashKillTool` | Shell 命令 |
| 记忆工具 | `SessionNoteTool` | 会话笔记 |
| MCP 工具 | `MCPTool` | 通过 MCP 协议调用外部服务 |
| 技能工具 | `SkillTool` | Claude Skills |

#### 设计要点

1. **统一接口**：所有工具继承 `Tool` 基类，Agent 无需关心具体实现
2. **双格式支持**：`to_schema()` 和 `to_openai_schema()` 适配不同 LLM 协议
3. **异步执行**：`execute()` 是 async 方法，支持 IO 密集型操作
4. **结果封装**：`ToolResult` 统一封装成功/失败状态

---

### Q9: 重试机制设计（装饰器模式）

**答：**

#### 核心设计

```python
# retry.py - 指数退避重试装饰器
@async_retry(RetryConfig(max_retries=3, initial_delay=1.0))
async def call_api():
    # API 调用代码
    pass
```

#### RetryConfig 配置

```python
class RetryConfig:
    enabled: bool = True              # 是否启用
    max_retries: int = 3              # 最大重试次数
    initial_delay: float = 1.0        # 初始延迟（秒）
    max_delay: float = 60.0           # 最大延迟（秒）
    exponential_base: float = 2.0     # 指数基数

    def calculate_delay(self, attempt: int) -> float:
        # 指数退避：delay = initial_delay * (base ^ attempt)
        delay = self.initial_delay * (self.exponential_base ** attempt)
        return min(delay, self.max_delay)
```

#### 执行流程

```
第1次失败 → 等待 1s → 重试
第2次失败 → 等待 2s → 重试
第3次失败 → 等待 4s → 重试
第4次失败 → 抛出 RetryExhaustedError
```

#### 设计亮点

1. **装饰器模式**：无侵入式，不修改业务代码
2. **指数退避**：避免雪崩效应，给服务恢复时间
3. **回调支持**：`on_retry` 回调用于 UI 显示重试状态
4. **专用异常**：`RetryExhaustedError` 携带最后一次异常和尝试次数

---

### Q10: 消息摘要机制（Memory 管理）

**答：**

#### 为什么需要摘要？

- LLM 有上下文长度限制（如 128K tokens）
- 长对话会导致上下文溢出
- 摘要可以压缩历史，保留关键信息

#### 双重 Token 检测

```python
# agent.py:198-205
estimated_tokens = self._estimate_tokens()  # 本地估算（tiktoken）
should_summarize = (
    estimated_tokens > self.token_limit or    # 本地超限
    self.api_total_tokens > self.token_limit  # API 返回超限
)
```

| 检测方式 | 优点 | 缺点 |
|----------|------|------|
| 本地估算 | 快速、预判 | 不够精确 |
| API 返回 | 精确 | 有滞后性 |
| **两者结合** | **既及时又准确** | - |

#### 摘要策略

```
保留结构：system → user1 → summary1 → user2 → summary2 → ...

原则：
1. 保留所有 user 消息（用户意图）
2. 摘要 assistant + tool 消息（执行过程）
3. 摘要调用 LLM 生成，简洁保留关键信息
```

---

### Q11: MCP 协议设计（三种连接方式）

**答：**

#### 什么是 MCP？

MCP（Model Context Protocol）是一种标准化协议，让 Agent 可以调用外部工具/服务。

#### 三种连接方式

| 类型 | 场景 | 示例 |
|------|------|------|
| **STDIO** | 本地子进程 | `npx @anthropic/mcp-server-memory` |
| **SSE** | HTTP 长连接 | 远程服务器 |
| **HTTP** | RESTful API | 简单 HTTP 调用 |

#### MCPTool 封装

```python
# mcp_loader.py
class MCPTool(Tool):
    def __init__(self, name, description, parameters, session, execute_timeout):
        self._session = session  # MCP 客户端会话

    async def execute(self, **kwargs) -> ToolResult:
        async with asyncio.timeout(timeout):
            result = await self._session.call_tool(self._name, arguments=kwargs)
        return ToolResult(success=not result.isError, content=content_str)
```

#### 超时保护

```python
@dataclass
class MCPTimeoutConfig:
    connect_timeout: float = 10.0   # 连接超时
    execute_timeout: float = 60.0   # 执行超时
    sse_read_timeout: float = 120.0 # SSE 读取超时
```

**为什么分三个超时？** 不同阶段的合理等待时间不同，分开配置更精细。

---

### Q12: 配置系统设计（三级优先级）

**答：**

#### 配置文件搜索顺序

```python
# config.py:177-206
def find_config_file(cls, filename: str) -> Path | None:
    # 优先级 1：开发模式（当前目录）
    dev_config = Path.cwd() / "mini_agent" / "config" / filename
    if dev_config.exists(): return dev_config

    # 优先级 2：用户配置目录
    user_config = Path.home() / ".mini-agent" / "config" / filename
    if user_config.exists(): return user_config

    # 优先级 3：包安装目录
    package_config = cls.get_package_dir() / "config" / filename
    if package_config.exists(): return package_config
```

#### 三级优先级的适用场景

| 优先级 | 路径 | 场景 |
|--------|------|------|
| 1 | `./mini_agent/config/` | 开发调试 |
| 2 | `~/.mini-agent/config/` | 用户自定义 |
| 3 | `<package>/config/` | 默认配置 |

#### Pydantic 配置验证

```python
class LLMConfig(BaseModel):
    api_key: str                          # 必填
    api_base: str = "https://api.minimax.io"  # 有默认值
    model: str = "MiniMax-M2.5"
    provider: str = "anthropic"
    retry: RetryConfig = Field(default_factory=RetryConfig)
```

**好处**：类型安全、自动验证、IDE 补全支持

---

## 学习总结

### Mini-Agent 核心架构一览

```
┌─────────────────────────────────────────────────────────────────────┐
│                    Mini-Agent 完整架构                               │
│                                                                     │
│  核心公式：Agent = LLM + Plan + Tools + Memory                       │
│                                                                     │
├─────────────────────────────────────────────────────────────────────┤
│  CLI 层 (cli.py)                                                    │
│  ├─ 外层循环：用户输入循环（等待输入 → 调用 Agent → 输出结果）         │
│  ├─ 参数解析、配置加载                                               │
│  └─ Esc 取消监听（设置 cancel_event）                                │
├─────────────────────────────────────────────────────────────────────┤
│  Agent 层 (agent.py)                                                │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  LLM                    │  Plan                             │   │
│  │  ├─ LLMClient (工厂)    │  ├─ Agent Loop (while 循环)       │   │
│  │  ├─ AnthropicClient     │  ├─ 取消检测 (_check_cancelled)   │   │
│  │  ├─ OpenAIClient        │  └─ 隐式规划（LLM 自行决策）       │   │
│  │  └─ 重试机制 (Retry)    │                                   │   │
│  ├─────────────────────────┼───────────────────────────────────┤   │
│  │  Tools                  │  Memory                           │   │
│  │  ├─ 内置工具            │  ├─ messages 消息历史              │   │
│  │  │  └─ Read/Write/Bash  │  ├─ 摘要机制 (summarize)          │   │
│  │  ├─ MCP 工具 (MCPTool)  │  └─ SessionNoteTool               │   │
│  │  └─ Skill 工具          │                                   │   │
│  └─────────────────────────┴───────────────────────────────────┘   │
├─────────────────────────────────────────────────────────────────────┤
│  Config 层 (config.py)                                              │
│  └─ 三级优先级：开发目录 > 用户目录 > 包目录                          │
└─────────────────────────────────────────────────────────────────────┘
```

### 核心设计决策

| 决策 | 选择 | 理由 |
|------|------|------|
| Plan 机制 | 隐式（LLM 自行规划） | 简单、依赖少 |
| LLM 抽象 | 策略模式 | 支持多 Provider |
| 重试机制 | 装饰器 + 指数退避 | 无侵入、防雪崩 |
| Token 检测 | 双重检测 | 及时 + 准确 |
| 配置系统 | 三级优先级 | 灵活适应不同场景 |

### Q13: Memory 机制详解（三层记忆）

**答：**

Mini-Agent 的 Memory 有三层机制：

```
┌─────────────────────────────────────────────────────────────────┐
│                    Mini-Agent Memory 机制                        │
├─────────────────────────────────────────────────────────────────┤
│  1️⃣ 短期记忆：self.messages（内存）                              │
│     ├─ 数据结构：list[Message]                                  │
│     ├─ 初始化：[system_prompt]                                  │
│     ├─ 追加：user → assistant → tool → assistant → ...         │
│     └─ 生命周期：单次会话，程序退出即清空                          │
├─────────────────────────────────────────────────────────────────┤
│  2️⃣ 摘要压缩：_summarize_messages()（内存优化）                  │
│     ├─ 触发条件：token 超限（本地估算 OR API 返回）               │
│     ├─ 策略：保留 user 消息，压缩 assistant+tool 消息            │
│     ├─ 实现：调用 LLM 生成摘要替换原消息                          │
│     └─ 结构：system → user1 → summary1 → user2 → summary2 → ...│
├─────────────────────────────────────────────────────────────────┤
│  3️⃣ 长期记忆：SessionNoteTool（文件持久化）                      │
│     ├─ 存储位置：./workspace/.agent_memory.json                 │
│     ├─ 触发方式：Agent 主动调用 record_note / recall_notes       │
│     ├─ 数据结构：[{timestamp, category, content}, ...]          │
│     └─ 生命周期：跨会话持久化                                    │
└─────────────────────────────────────────────────────────────────┘
```

#### 1. 短期记忆：self.messages

```python
# agent.py:76 - 初始化
self.messages: list[Message] = [Message(role="system", content=system_prompt)]

# agent.py:88 - 追加用户消息
self.messages.append(Message(role="user", content=content))

# agent.py:404 - 追加 LLM 响应
self.messages.append(assistant_msg)
```

**本质**：Python 列表，存在内存里，程序退出即清空。

#### 2. 摘要压缩：_summarize_messages()

```python
# 双重检测触发
should_summarize = (
    estimated_tokens > self.token_limit or    # 本地估算超限
    self.api_total_tokens > self.token_limit  # API 返回超限
)
```

**摘要策略**：

```
原始：system → user1 → assistant1 → tool1 → assistant2 → user2 → ...
压缩：system → user1 → summary1 → user2 → summary2 → ...
              (保留)   (压缩)     (保留)   (压缩)
```

#### 3. 长期记忆：SessionNoteTool

```python
# Agent 可以主动调用
record_note("用户偏好简洁回复", category="user_preference")
recall_notes()  # 获取所有笔记
```

**存储格式**（JSON 文件）：

```json
[{"timestamp": "2026-02-15T14:30:00", "category": "user_preference", "content": "用户偏好简洁回复"}]
```

#### 对比总结

| 类型 | 存储位置 | 触发方式 | 生命周期 | 用途 |
|------|----------|----------|----------|------|
| 短期记忆 | `self.messages` 内存 | 自动 | 单次会话 | 当前对话上下文 |
| 摘要机制 | 内存（替换原消息） | Token 超限时 | 单次会话 | 压缩历史，防溢出 |
| 长期记忆 | JSON 文件 | Agent 主动调用 | 跨会话 | 用户偏好、重要决策 |

---

### 如果从零实现，最小可用版本需要：

1. **必须**：Agent Loop + LLM 调用 + 1 个 Tool
2. **建议**：重试机制 + 消息历史
3. **锦上添花**：摘要、MCP、Skills、配置系统

